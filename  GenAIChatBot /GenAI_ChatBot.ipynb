{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmBTii3SWdwG",
        "outputId": "63de3fbe-3202-4053-fcef-d214ec2f09b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m41.0/41.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m855.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Source for Google GenAI Embeddings in LangChain\n",
        "\n",
        "https://python.langchain.com/docs/integrations/text_embedding/google_generative_ai/\n",
        "\n",
        "# Source to Embedding Models\n",
        "\n",
        "https://python.langchain.com/docs/integrations/text_embedding/"
      ],
      "metadata": {
        "id": "P11BCZ5vviER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDC1auJEmzla",
        "outputId": "30cb5b68-ea12-4ed8-c132-9f12edc3a22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GOOGLE_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List of Google AI Models\n",
        "https://ai.google.dev/gemini-api/docs/models/gemini\n"
      ],
      "metadata": {
        "id": "XdRcBjUUvsxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "chatbot = GoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)\n",
        "\n",
        "# create a message\n",
        "msg = HumanMessage(content=input(\"Hello. How can I help?\\n\"), name=\"Saranya\")\n",
        "\n",
        "# message list\n",
        "messages = [msg]\n",
        "\n",
        "chatbot.invoke(messages)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "7AirbewmnOGv",
        "outputId": "5352d4b7-77ec-44f0-e7d2-040a00b24449"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello. How can I help?\n",
            "What color is a banana?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yellow (when ripe)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trying to loop to continuously ask"
      ],
      "metadata": {
        "id": "9htfdlpQQd9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  #print(\"starting here\")\n",
        "  content1 = input(\"Hello. How can I help?\\n\")\n",
        "  msg = HumanMessage(content=content1, name=\"User\")\n",
        "\n",
        "\n",
        "  if content1.lower() == \"bye\":\n",
        "    print(\"Bye!\")\n",
        "    break\n",
        "\n",
        "  messages = [msg]\n",
        "  output = chatbot.invoke(messages)\n",
        "  print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB6BT47nQdqC",
        "outputId": "a25f53ff-1a1e-49dc-f30b-d92a29297562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello. How can I help?\n",
            "What number comes after 2?\n",
            "3\n",
            "\n",
            "Hello. How can I help?\n",
            "What is the capital of California?\n",
            "Sacramento\n",
            "\n",
            "Hello. How can I help?\n",
            "Bye\n",
            "Bye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Cases Showing Different Prompting Techniques\n",
        "Zero-Shot Prompting"
      ],
      "metadata": {
        "id": "_JN0oW3SFda_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_msg = SystemMessage(content=\"Translate everything the user says into Tamil.\")\n",
        "\n",
        "while True:\n",
        "  content1 = input(\"Hello. How can I help?\\n\")\n",
        "  human_msg = HumanMessage(content=content1, name=\"User\")\n",
        "\n",
        "\n",
        "  if content1.lower() == \"bye\":\n",
        "    print(\"Bye!\")\n",
        "    break\n",
        "\n",
        "  messages = [system_msg, human_msg]\n",
        "  output = chatbot.invoke(messages)\n",
        "  print(output)"
      ],
      "metadata": {
        "id": "-ZP_sFcI50in"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}